name: Monthly Evals

on:
  schedule:
    # Run on the 1st of every month at 2am UTC
    - cron: '0 2 1 * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  run-evals:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4
        with:
          version: 10

      - uses: actions/setup-node@v4
        with:
          node-version: 24
          cache: pnpm

      - name: Install dependencies
        run: pnpm install

      - name: Run evaluations
        run: |
          timeout --preserve-status 90 pnpm eval --threshold=85 --outputPath=results.json | tee eval-output.txt
          EXIT_CODE=${PIPESTATUS[0]}

          # Generate markdown summary from JSON
          if [ -f results.json ]; then
            node -e '
            const data = require("./results.json");
            const run = data.run;
            const suites = data.suites;

            let md = "# ðŸ“Š Evaluation Results\n\n";
            md += `**Run ID:** ${run.id} | **Type:** ${run.runType} | **Date:** ${new Date(run.createdAt).toLocaleString()}\n\n`;

            // Summary table
            md += "## Summary\n\n";
            md += "| Suite | Score | Status | Duration |\n";
            md += "|-------|-------|--------|----------|\n";

            for (const suite of suites) {
              const score = (suite.averageScore * 100).toFixed(1);
              const icon = suite.status === "success" ? "âœ…" : "âŒ";
              const duration = (suite.duration / 1000).toFixed(2);
              md += `| ${suite.name} | ${score}% | ${icon} ${suite.status} | ${duration}s |\n`;
            }

            // Details per suite
            md += "\n## Details\n\n";
            for (const suite of suites) {
              md += `### ${suite.name}\n\n`;
              md += "| # | Score | Scorers | Duration |\n";
              md += "|---|-------|---------|----------|\n";

              for (const ev of suite.evals) {
                const score = (ev.averageScore * 100).toFixed(0);
                const scorers = ev.scores.map(s => `${s.name}: ${(s.score * 100).toFixed(0)}%`).join(", ");
                const dur = (ev.duration / 1000).toFixed(2);
                md += `| ${ev.colOrder + 1} | ${score}% | ${scorers} | ${dur}s |\n`;
              }
              md += "\n";
            }

            console.log(md);
            ' >> $GITHUB_STEP_SUMMARY
          else
            echo "# âŒ Evaluation Failed" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat eval-output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

          exit $EXIT_CODE
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MCP_URL: ${{ secrets.MCP_URL }}

      - name: Upload eval results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.run_number }}
          path: eval-output.txt
          retention-days: 90

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Monthly Eval Failed - ${new Date().toISOString().split('T')[0]}`,
              body: `The monthly MCP evaluation failed.\n\n**Run:** ${runUrl}\n\nCheck the [artifacts](${runUrl}) for detailed results.`,
              labels: ['evals', 'automated']
            });
